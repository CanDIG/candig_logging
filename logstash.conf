# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
  file {
    path => "/home/dnaidoo/Documents/federation_service/log/federation.log"
    type => "federation"
  }
  file {
    path => "/tmp/tyk/*.csv"
    type => "tyk_analytics_csv"    
  }
}

filter {
  if [type] == "tyk_analytics_csv" {
    csv {
      #autodetect_column_names => true
      columns => [
	"Method", "Host", "Path", "RawPath", "ContentLength", "UserAgent", "Day",
	"Month", "Year", "Hour", "ResponseCode", "APIKey", "TimeStamp", "APIVersion",
	"APIName", "APIID", "OrgID", "OauthID", "RequestTime", "RawRequest", "RawResponse",
	"IPAddress", "Geo", "Tags", "Alias", "TrackPath", "ExpireAt"    

      ]
      remove_field => [ "RawResponse" ]
    }
    ruby {
      #add_field => [ "decodeRequest" ]
      #code => 'event.set("decodedRequest", Base64.decode64(event.get("RawRequest")))'
        
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://10.9.208.132:9200"]
    #index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
  stdout { codec => rubydebug }
}
